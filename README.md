# ğŸ“š RAG Knowledge Assistant (AI Agent)

A **production-grade Retrieval-Augmented Generation (RAG) Knowledge Assistant** built using **Python, Ollama, FAISS, LangGraph, and FastAPI**.  
This system enables **accurate, document-grounded Q&A** over heterogeneous data sources such as **PDF, DOCX, TXT, and Excel files**, using a clean **AI agent orchestration architecture**.

---

## ğŸš€ Key Features

- ğŸ“„ **Multi-Document Support** â€” PDF, DOCX, TXT, XLS/XLSX  
- ğŸ§  **RAG Pipeline** â€” Prevents hallucinations by grounding answers in documents  
- ğŸ” **Semantic Search** â€” FAISS vector database for meaning-based retrieval  
- ğŸ¤– **AI Agent Architecture** â€” LangGraph-based deterministic agent workflow  
- âš¡ **Local LLMs** â€” Ollama (no API keys, private, cost-free)  
- ğŸŒ **FastAPI Backend** â€” Async, scalable REST API  
- ğŸ§© **Extensible Design** â€” Ready for multi-agent, tools, and observability  

---

## ğŸ—ï¸ High-Level Architecture

```
Documents (PDF / DOCX / TXT / Excel)
        â†“
Document Ingestion & Chunking
        â†“
Embeddings (Ollama â€“ nomic-embed-text)
        â†“
Vector Store (FAISS)
        â†“
Semantic Retrieval
        â†“
LLM Generation (Ollama â€“ llama3)
        â†“
LangGraph Agent Orchestration
        â†“
FastAPI REST Endpoint
```

---

## ğŸ§  Why RAG?

Traditional LLMs answer questions based only on training data, which can cause:
- âŒ Hallucinations  
- âŒ Outdated or incorrect answers  
- âŒ No control over knowledge sources  

This project uses **Retrieval-Augmented Generation (RAG)** to ensure:
- âœ… Answers are grounded in your documents  
- âœ… Higher accuracy and reliability  
- âœ… Enterprise-ready AI behavior  

---

## ğŸ§‘â€ğŸš€ Agent Design (LangGraph)

The system is modeled as an **AI Agent** using **LangGraph**, represented as a state machine:

```
START
  â†“
Retrieve Relevant Context (FAISS)
  â†“
Generate Answer (LLM)
  â†“
END
```

### Agent State (Pydantic)

```python
class AgentState(BaseModel):
    question: str
    context: str = ""
    answer: str = ""
```

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-----|-----------|
| Language | Python |
| API Framework | FastAPI |
| Agent Orchestration | LangGraph |
| LLM Runtime | Ollama |
| Embeddings Model | nomic-embed-text |
| Chat Model | llama3 |
| Vector Database | FAISS |
| Document Processing | LangChain |
| Server | Uvicorn |

---

## ğŸ“‚ Project Structure

```
rag-knowledge-assistant/
â”‚
â”œâ”€â”€ app.py               # FastAPI entry point
â”œâ”€â”€ ingest.py            # Multi-format document ingestion
â”œâ”€â”€ embeddings.py        # Ollama embeddings
â”œâ”€â”€ vector_store.py      # FAISS vector database
â”œâ”€â”€ llm.py               # Ollama LLM wrapper
â”œâ”€â”€ qa.py                # RAG Q&A logic
â”œâ”€â”€ agent_state.py       # Agent state (Pydantic)
â”œâ”€â”€ agent_nodes.py       # LangGraph nodes
â”œâ”€â”€ agent_graph.py       # LangGraph workflow
â”‚
â”œâ”€â”€ data/                # Input documents
â””â”€â”€ README.md
```

---

## âš™ï¸ Setup Instructions

### Install Ollama
https://ollama.com

```bash
ollama pull nomic-embed-text
ollama pull llama3
```

### Create Virtual Environment

```bash
python -m venv .venv
source .venv/bin/activate
```

### Install Dependencies

```bash
pip install fastapi uvicorn langchain langchain-community faiss-cpu docx2txt unstructured openpyxl pandas langgraph
```

### Run API

```bash
uvicorn app:app --reload
```

Open:
http://127.0.0.1:8000/docs

---

## ğŸ¯ Use Cases

- Internal knowledge assistant  
- SOP and policy Q&A  
- Onboarding automation  
- Enterprise document search  

---

## ğŸ‘¤ Author

Built by **Pawan Ashok Shinde**  
AI Agent Engineer | Python | LangGraph | RAG
